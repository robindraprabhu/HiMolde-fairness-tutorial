{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hands-on tutorial\n",
        "\n",
        "This tutorial is a slightly modified version of the tutorial [\"An Intersectional Approach to Model Construction and Evaluation in Mental Health Care (Online)\"](https://facctconference.org/2022/acceptedtuts#construct) by Marta Maslej (CAMH), Laura Sikstrom (CAMH), Darla Reslan (Toronto) and Yifan Wang (McMaster) given at ACT FAccT 2022.\n",
        "\n",
        "The tutorial makes use of simulated data. Some of the categories in the original dataset have been remaped to more abstract categories. The modified dataset is entirely fictitious and the dataset should only be viewed as an illustrative artefact for the purposes of this tutorial.\n",
        "\n",
        "This tutorial makes use of fairlearn-package (learn more on fairlearn.org) and a full version of the original tutorial can be found [here](https://fairlearn.org/v0.11/auto_examples/plot_intersectional_bias.html#sphx-glr-auto-examples-plot-intersectional-bias-py)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hypothetical scenario\n",
        "\n",
        "You work in a national public health agency. Another team in the agency has created a model to predict the diagnosis of affective disorder (0) or schizophrenia (1). The team claims a performance above known human accuracy levels, and the agency is excited to deploy the model in a country wide trial.\n",
        "\n",
        "Before the model can be trialled, they contact your team to help assess the fairness of this model. You are given\n",
        "\n",
        "* the model\n",
        "* the training set\n",
        "* the test set\n",
        "\n",
        "Your task is to inspect model fairness with respect to region and gender, and to report any problems back to the production team."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAj6Ig0wi_XU"
      },
      "source": [
        "### Setup \n",
        "\n",
        "Please run this at the start!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# if running on colab\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "##!pip install fairlearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3hxXmjebFo1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.metrics as skm\n",
        "import seaborn as sns\n",
        "\n",
        "#!pip install fairlearn\n",
        "\n",
        "import utils\n",
        "\n",
        "#%load_ext autoreload\n",
        "#%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bUmTfdZbgiH"
      },
      "outputs": [],
      "source": [
        "#read in train and test sets\n",
        "train = utils.fetch_data(\"train.csv\", remap_cols=('Race','Region'), remap_vals=utils.remap_race)\n",
        "test  = utils.fetch_data(\"test.csv\", remap_cols=('Race','Region'), remap_vals=utils.remap_race)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6wX6eBUiyZW"
      },
      "source": [
        "### Exploring the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WY2twajnfJl9",
        "outputId": "a453e605-de57-4276-e034-5cd3a51b4fcc"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhmAkPGaQ7Ed",
        "outputId": "836267d9-2f0d-44e7-b77d-a6a7adb4bf57"
      },
      "outputs": [],
      "source": [
        "# Add a category for train vs test, and create a merged dataframe containing both train and test\n",
        "train[\"set\"] = \"train\"\n",
        "test[\"set\"] = \"test\"\n",
        "all = pd.merge(train, test, on = list(train.columns), how='outer')\n",
        "\n",
        "# Format graphs\n",
        "variables_to_inspect = [\"Diagnosis\",\"Region\", \"Sex\"]\n",
        "dist = {}\n",
        "for var in variables_to_inspect:\n",
        "    dist[var] = utils.group_pivot(\"set\", var, all)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#diagnosis = utils.group_pivot(\"set\", \"Diagnosis\", all)\n",
        "#sex = utils.group_pivot(\"set\", \"Region\", all)\n",
        "#region = utils.group_pivot(\"set\", \"Sex\", all)\n",
        "\n",
        "#fig, axs = plt.subplots(1, 3, figsize=(20,4))\n",
        "fig, axs = plt.subplots(1, len(dist), figsize=(20,4))\n",
        "#diagnosis[[1, 0]].plot.barh(stacked=True, ax = axs[0])\n",
        "dist[\"Diagnosis\"][[1,0]].plot.barh(stacked=True, ax=axs[0])\n",
        "\n",
        "axs[0].set_title('Diagnosis across train and test sets')\n",
        "#sex.plot.barh(stacked=True, ax = axs[1])\n",
        "dist[\"Region\"].plot.barh(stacked=True, ax = axs[1])\n",
        "\n",
        "axs[1].set_title('Region across train and test sets')\n",
        "#region.plot.barh(stacked=True, ax = axs[2])\n",
        "dist[\"Sex\"].plot.barh(stacked=True, ax = axs[2])\n",
        "\n",
        "axs[2].set_title('Sex across train and test sets')\n",
        "fig.show()\n",
        "\n",
        "# Drop the new categories added at the start\n",
        "train = train.drop(\"set\", axis = 1)\n",
        "test = test.drop(\"set\", axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMSQL0PWi76z"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Tte-OJJlj1e"
      },
      "outputs": [],
      "source": [
        "#Split the data into x (features) and y (diagnosis)\n",
        "train_x, train_y = utils.preprocess_data(train, target='Diagnosis')\n",
        "test_x, test_y = utils.preprocess_data(test, target='Diagnosis')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRmNz0cUxyeV"
      },
      "source": [
        "We need to convert categorical variables to something the algorithm can understand, so we need to split them up into \"dummy variables\" which either have a value of 0 or 1. Here's an example:\n",
        "\n",
        "```\n",
        "Gender =  [M, F, F, M] \n",
        "\n",
        "# Will be mapped to\n",
        "\n",
        "Gender.M = [1, 0, 0, 1]\n",
        "Gender.F = [0, 1, 1, 0]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lu9NUJgxsqp"
      },
      "outputs": [],
      "source": [
        "categories=[\"Sex\", \"Region\", \"Housing\", \"Delay\"] # Categorial variables\n",
        "\n",
        "\n",
        "# Apply transformation to data\n",
        "train_x = train_x.join(utils.onehot(train_x, categories=categories))\n",
        "test_x = test_x.join(utils.onehot(test_x,categories=categories))\n",
        "\n",
        "#Drop the original categories\n",
        "train_x = train_x.drop(categories, axis = 1)\n",
        "test_x = test_x.drop(categories, axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_Jriw6Hz689"
      },
      "source": [
        "### Train and evaluate model\n",
        "\n",
        "Let's build the model and see if we can reproduce the performance reported by the developing team."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ioVomNF0ei6H"
      },
      "outputs": [],
      "source": [
        "# Defining a logistic regression model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression(penalty = \"elasticnet\", max_iter=1000, \n",
        "                           solver = \"saga\", l1_ratio=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hpZG7P4tw77",
        "outputId": "4cbf42db-464d-4938-eda6-bb2561e60b28"
      },
      "outputs": [],
      "source": [
        "# Training the model with all available features\n",
        "model.fit(train_x, train_y)\n",
        "\n",
        "#generate 10000 predictions for 10000 train individuals\n",
        "train_predictions = model.predict(train_x)\n",
        "\n",
        "#generate 1000 predictions for 1000 test individuals\n",
        "test_predictions = model.predict(test_x)\n",
        "\n",
        "\n",
        "print(\"Accuracy: \\n train: {} | test: {} \".format(skm.accuracy_score(train_y, train_predictions), \n",
        "                                                  skm.accuracy_score(test_y, test_predictions))\n",
        "                                                  ) #Training accuracy / test accuracy\n",
        "\n",
        "\n",
        "utils.confusion_matrix(test_y, test_predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The model has a high accuracy and a very low misclassification rate. It looks good. But how \"fair\" is it?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gpL8ILtyXTC"
      },
      "source": [
        "## Fairness assessment\n",
        "\n",
        "You are now ready to assess the fairness with respect to the various regions where the model will be deployed. Various fairness metrics may be relevant. To make our selection, we consider the harm caused by a misclassification. What do you consider more ominous:\n",
        "\n",
        "\n",
        "* misdiagnosing individuals with SZ as having AD (*false negative*)\n",
        "\n",
        "or \n",
        "\n",
        "* misdiagnosing individuals with AD as having SZ (*false positive*)?\n",
        "\n",
        "\n",
        "Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4U8W0o7oLdw2"
      },
      "source": [
        "#### Examination of regional bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "utils.eval_fairness(test_y, test_predictions, sensitive_var=test['Region'], sensitive_ref='Sør-Øst', metric=\"FPR\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waqkxMlBLLVP"
      },
      "source": [
        "- First row shows the metric (false positive rates)\n",
        "- Second row shows parity (the ratio of the metric between specified group and reference)\n",
        "\n",
        "False positive rates are low, but disparities in performance are emerging (e.g., patients in Midt-Norge and Nord groups are more likely to be misdiagnosed with SZ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gOqtEjDLf37"
      },
      "source": [
        "## Intersectional bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbUKVJVqLh_Z"
      },
      "source": [
        "However, we suspect this bias might only extend to identities defined by the intersecting features of SEX and REGION, so we repeat this analysis for these subgroups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sensitive_var ='Region'\n",
        "intersect_var = 'Sex'\n",
        "\n",
        "\n",
        "m = sns.FacetGrid(train, row = intersect_var, col = sensitive_var)\n",
        "m.map(sns.histplot, \"Diagnosis\", discrete = True, shrink = .8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "utils.intersectionalf(test_y, test_predictions, test=test,\n",
        "                 sensitive_var='Region', sensitive_ref='Sør-Øst', \n",
        "                 intersect_var='Sex', intersect_ref='Male', \n",
        "                 metric=\"FPR\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that *men* in *Midt-Norge* are generally more likely to be diagnosed with SZ and almost twice as likely as men in *Sør-Øst*. \n",
        "\n",
        "The developing team is perturbed and suggests that the model might be picking up on this trend. They suggest removing \"Region\" as feature in the model in order to make it \"unaware\" of \"Region\". \n",
        "\n",
        "Do you think removing \"Region\" as feature will \n",
        "\n",
        "a) improve the FPR for southern men?\n",
        "\n",
        "b) worsen the FPR for southern men?\n",
        "\n",
        "c) have no impact on the FPR?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWc0WH_LhTKs"
      },
      "source": [
        "### Retrain without \"Region\"\n",
        "\n",
        "Let's remove \"Region\" and see what happens..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tLG3vFjkAxB"
      },
      "outputs": [],
      "source": [
        "# drop Region-features from train and test\n",
        "sensitive_var = \"Region\"\n",
        "region_cat = [sensitive_var+\"_\"+v for v in utils.remap_race.values()]\n",
        "train_x_unaware = train_x.drop(region_cat, axis = 1)\n",
        "test_x_unaware = test_x.drop(region_cat, axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxaTHvJdgGYI",
        "outputId": "720eb3da-a51c-4a0e-b0e5-a0bf273471fb"
      },
      "outputs": [],
      "source": [
        "# Train and evaluate a model that is \"unaware\" of / blind to the feature \"Region\"\n",
        "\n",
        "model_unaware = LogisticRegression(penalty = \"elasticnet\", max_iter=1000, \n",
        "                           solver = \"saga\", l1_ratio=1)\n",
        "model_unaware = model_unaware.fit(train_x_unaware, train_y)\n",
        "\n",
        "train_predictions = model_unaware.predict(train_x_unaware)\n",
        "test_predictions = model_unaware.predict(test_x_unaware)\n",
        "print(\"Accuracy: \\n train: {} | test: {} \".format(skm.accuracy_score(train_y, train_predictions), \n",
        "                                                  skm.accuracy_score(test_y, test_predictions)) \n",
        "                                                  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwPOBIWhhaj9",
        "outputId": "ff4c91e7-d4ac-4f30-ebfd-22c31d5678b0"
      },
      "outputs": [],
      "source": [
        "utils.eval_fairness(test_y, test_predictions, sensitive_var=test['Region'], sensitive_ref='Sør-Øst', metric='FPR')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VF6tj96PMY2Y"
      },
      "source": [
        "Did removing \"Region\" from the model fix our problem? How is our new model doing overall?\n",
        "How many individuals with AD has it misclassified as having SZ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Differences in base distributions\n",
        "\n",
        "Making the model unaware of \"Region\" did not improve the situation. Instead it seems to have made it worse. Why is that?\n",
        "\n",
        "Let's have a look at some base distributions. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# list the variables\n",
        "print(train.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's first look at the features \"Anhedonia\", \"Appetite\" and \"Delusion\":"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for v in [\"Anhedonia\", \"Appetite\", \"Concentration\"]:\n",
        "    utils.plot_base_histogram(data=train, inspect_var=v, break_down_on=\"Region\", bins=25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's have a look at a few more:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for v in [\"Withdrawal\", \"Delusion\"]:\n",
        "    utils.plot_base_histogram(data=train, inspect_var=v, break_down_on=\"Region\", bins=25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we see that the distributions are more out of phase. The effect is more pronounced between the southern and northern distributions. Differences in base distributions between \"populations\" will manifest as differences in error rates and outcomes. \n",
        "\n",
        "What are likely reasons for these shifts?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "H6wX6eBUiyZW",
        "rMSQL0PWi76z"
      ],
      "name": "Intersectional Bias Assessment (Part 2) - Python",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
